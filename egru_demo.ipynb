{"cells":[{"cell_type":"markdown","metadata":{},"source":["Event based GRU was publised as a conference paper at ICLR 2023: \n","\n","**Efficient recurrent architectures through activity sparsity and sparse back-propagation through time (notable-top-25%)**\n","\n","![egru_qr](media/egru_paper_qr.png \"egru_qr\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":225},"collapsed":true,"executionInfo":{"elapsed":24326,"status":"ok","timestamp":1720447876873,"user":{"displayName":"khaleel khan","userId":"09242389570118408279"},"user_tz":-120},"id":"wlqNkcoPIyyU","outputId":"d074756e-64e5-4fb2-cd15-c40a7b480376"},"outputs":[],"source":["import os\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import json\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":538},"collapsed":true,"executionInfo":{"elapsed":22295,"status":"ok","timestamp":1720447899137,"user":{"displayName":"khaleel khan","userId":"09242389570118408279"},"user_tz":-120},"id":"umTUC2CULtf3","outputId":"2f3e4963-2fd5-4720-b673-3238bf04dce1"},"outputs":[],"source":["%pip install git+https://github.com/Efficient-Scalable-Machine-Learning/EvNN.git@feature/egru_cell"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":41,"status":"ok","timestamp":1720447899138,"user":{"displayName":"khaleel khan","userId":"09242389570118408279"},"user_tz":-120},"id":"8DgMDZYEIyyW","outputId":"4ac3d827-f598-4a78-91ce-19e4879ffc39"},"outputs":[],"source":["from evnn_pytorch import EGRU"]},{"cell_type":"markdown","metadata":{},"source":["<!-- ![EGRUanim](https://github.com/Efficient-Scalable-Machine-Learning/EvNN/raw/main/media/videos/anim/1080p60/EvNNPlot_ManimCE_v0.17.2.gif \"egru\") -->\n","\n","<img src=\"https://github.com/Efficient-Scalable-Machine-Learning/EvNN/raw/main/media/videos/anim/1080p60/EvNNPlot_ManimCE_v0.17.2.gif\" alt=\"egru\" width=\"1000\"/>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":243},"id":"TU-I_wVcNEzN"},"outputs":[],"source":["# Download and unzip the trained model\n","!wget -q -O download.zip https://datashare.tu-dresden.de/s/jbzaoqFXwCLYHJF/download\n","!unzip -o download.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5w1NsdCyIyyZ"},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S4oIiaaMIyya"},"outputs":[],"source":["# load ascii mapping\n","filename = \"Enwik8/index2word.json\"\n","with open(filename, 'r', encoding='utf-8') as fp:\n","    i2w = json.load(fp)\n","\n","filename = \"Enwik8/word2index.json\"\n","with open(filename, 'r', encoding='utf-8') as fp:\n","    w2i = json.load(fp)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hbqnG49lIyya"},"outputs":[],"source":["eos = w2i.pop(\"<eos>\")\n","w2i = {chr(int(c)):i for c,i in w2i.items()}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pDdDu53oIyyc"},"outputs":[],"source":["n_vocab = len(i2w)\n","print(\"Total Vocab: \", n_vocab)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xO3YqVJ5Iyyd"},"outputs":[],"source":["from typing import Union\n","\n","\n","class Decoder(nn.Module):\n","    def __init__(self,\n","                 ninp: int,\n","                 ntokens: int,\n","                 project: bool = False,\n","                 nemb: Union[None, int] = None,\n","                 dropout: float = 0.0):\n","        \"\"\"\n","        Takes hidden states of RNNs, optionally applies a projection operation and decodes to output tokens\n","        :param ninp: Input dimension\n","        :param ntokens: Number of tokens of the language model\n","        :param project: If True, applies a linear projection onto the embedding dimension\n","        :param nemb: If projection is True, specifies the dimension of the projection\n","        :param dropout: Dropout rate applied to the projector\n","        \"\"\"\n","        super(Decoder, self).__init__()\n","\n","        if project:\n","            assert nemb, \"If projection is True, must specify nemb!\"\n","\n","        self.ninp = ninp\n","        self.nemb = nemb if nemb else ninp\n","        self.nout = ntokens\n","\n","        self.dropout = dropout\n","\n","        # projector\n","        self.project = project\n","        if project:\n","            self.projection = nn.Linear(ninp, nemb)\n","        else:\n","            self.projection = nn.Identity()\n","\n","        # word embedding decoder\n","        self.decoder = nn.Linear(self.nemb, self.nout)\n","        nn.init.zeros_(self.decoder.bias)\n","\n","    def forward(self, x):\n","        bs, seq_len, ninp = x.shape\n","        if self.project:\n","            x = x.view(-1, ninp)\n","            x = F.relu(self.projection(x))\n","            x = x.view(bs, seq_len, self.nemb)\n","        x = x.view(-1, self.nemb)\n","        x = self.decoder(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cic03CDAIyye"},"outputs":[],"source":["class CharModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.embeddings = nn.Embedding(n_vocab, 400)\n","        self.rnns = nn.ModuleList([\n","        EGRU(400, 800, batch_first=False),\n","        EGRU(800, 800, batch_first=False),\n","        EGRU(800, 800, batch_first=False)]\n","        )\n","        self.decoder = Decoder(ninp=800, ntokens=n_vocab,\n","                               project=True, nemb=400)\n","\n","    def forward(self, x, y_pre=[None]*3, h_pre=[None]*3):\n","        y_new=[]\n","        h_new=[]\n","        x = self.embeddings(x)\n","        x, h, _ = self.rnns[0].step(x.squeeze(0), y_pre[0], h_pre[0])\n","        y_new.append(x.detach().clone())\n","        h_new.append(h.detach().clone())\n","        x, h, _ = self.rnns[1].step(x, y_pre[1], h_pre[1])\n","        y_new.append(x.detach().clone())\n","        h_new.append(h.detach().clone())\n","        x, h, _ = self.rnns[2].step(x, y_pre[2], h_pre[2])\n","        y_new.append(x.detach().clone())\n","        h_new.append(h.detach().clone())\n","\n","        # produce output\n","        x = self.decoder(x.unsqueeze(0))\n","        return x, y_new, h_new"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HHo4VF2hIyyf"},"outputs":[],"source":["model = CharModel().to(device)\n","model.eval()\n","model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sC4EPoGqIyyg"},"outputs":[],"source":["# Generation using the trained model\n","best_model = torch.load(\n","    \"Enwik8/2024-05-16-Enwik8-EGRU-trained/checkpoints/EGRU_best_model.cpt\", map_location=device)\n","model.load_state_dict(best_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PKko2hldIyyi"},"outputs":[],"source":["use_prompt = True\n","if use_prompt:\n","    ## With a prompt\n","    prompt = \"As with other Linux distributions, all of the editions can run on a computer alone, or in a\"\n","\n","    x = [w2i[c] for c in prompt]\n","else:\n","    ## Or with random starting character\n","    c = np.random.choice(list(\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"),1)[0]\n","    x = [w2i[c]]\n","    prompt = chr(int(i2w[x[0]]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ycxj3TTiAz5q"},"outputs":[],"source":["# Process prompt\n","x = np.reshape(x, (len(x), 1))\n","x = torch.tensor(x, dtype=torch.int, device=device)\n","state = [None]*3\n","internal_state = [None]*3\n","for token in x:\n","  y, state, internal_state = model(token.view(1,1), state, internal_state)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"59LLidh3Iyyj"},"outputs":[],"source":["temperature = 0.3\n","\n","print(prompt, end=\"\")\n","generated =  \"\"\n","# token = int(y[-1].argmax())\n","token = int(F.softmax(y[-1]/temperature, dim=0).multinomial(1))\n","x = torch.tensor(token, device=device).view(1,1)\n","for i in range(2000):\n","    y, state, internal_state = model(x, state, internal_state)\n","    # token = int(y[-1].argmax())\n","    token = int(F.softmax(y[-1]/temperature, dim=0).multinomial(1))\n","    x = torch.tensor(token, device=device).view(1,1)\n","    # with out:\n","    if token == eos:\n","        print(\"\\n\")\n","        break\n","    else:\n","        char = chr(int(i2w[token]))\n","        generated += char\n","        print(char, end=\"\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%pip install git+https://github.com/peter17/pijnu\n","%pip install -v mediawiki-parser"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from IPython.display import HTML, display\n","\n","def set_css(css):\n","  display(HTML('''\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  '''))\n","get_ipython().events.register('pre_run_cell', set_css)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xuOiwaatq-Rk"},"outputs":[],"source":["from mediawiki_parser.preprocessor import make_parser\n","preprocessor = make_parser({})\n","from mediawiki_parser.html import make_parser\n","\n","output = make_parser().parse(preprocessor.parse(generated).leaves())\n","display(HTML(output[:]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YjC7LSjMuR3j"},"outputs":[],"source":[]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
